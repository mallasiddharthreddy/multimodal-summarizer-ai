
# Multimodal Summarizer AI

Audio, Text, and Document Summarization with Transformer Models + Evaluation UI


# Overview

This project enables users to summarize audio files, raw text, and .docx documents using state-of-the-art transformer models (BART (Fine-tuned), PEGASUS, T5). The Streamlit interface supports summary generation, model comparison, sentiment analysis, and evaluation metric visualization. A downloadable PDF report is also generated.


# Key Features

âœ… Supports Audio, Text, and Document inputs

âœ… Uses Whisper for audio transcription

âœ… Offers BART (Fine-tuned), PEGASUS, and T5 summarizers

âœ… Generates summary reports as downloadable PDFs

âœ… Computes Cosine Similarity and BERTScore

âœ… Includes sentiment analysis of input

âœ… Supports side-by-side model comparison and metric visualization



# Models Used

| Model             | Task Type    | Source                              |
| ----------------- | ------------ | ----------------------------------- |
| BART (Fine-tuned) | Abstractive  | `models/bart-meetingbank-finetuned` |
| PEGASUS           | Abstractive  | `google/pegasus-xsum`               |
| T5                | Abstractive  | `t5-small`                          |
| Whisper           | Audio â†’ Text | `openai/whisper`                    |




# App Interface

### Home â€“ Upload Options
![Home Interface](images/ui_streamlit.png)

### Uploading an Audio File
![Uploading Audio File](images/uploaded_audio.png)

### Transcription and Sentiment Analysis
![Transcription + Sentiment](images/transcription_sentiment.png)

### Model Comparison and Metric Visualization (clicking on compare all models toggle from above)
![Comparison & Chart](images/model_comparison_chart.png)

### Choosing a Summarization Model based on metrics above
![Choose Model Dropdown](images/choose_model_dropdown.png)

### Generated Summary, Metrics, and PDF Export
![Summary + Metrics + PDF](images/summary_metrics_pdflink.png)


# Sample Summary Report
  
View a full example of the summary and evaluation for an uploaded audio file using the BART model:  
ðŸ‘‰ [Download Summary Report (PDF)](reports/summary_report-1.pdf)


# How It Works

1) Input: User uploads audio (.wav, .mp3), text, or document (.docx)

2) Processing:

- Audio is transcribed using Whisper

- Text is split into chunks (if lengthy)

3) Summarization: Selected model generates summaries

4) Evaluation: Two key metrics are computed:

- Cosine Similarity (TF-IDF)

- BERTScore (F1)

5) Sentiment Analysis: Performed using TextBlob

6) Export: PDF report is generated for download



## Evaluation & Benchmarking

Metrics auto-generated in:

```bash
  results/summary_outputs.csv
  results/model_metrics.csv
```
For graphing:

```bash
  python3 -m evaluation.visualizations
```


## Project Structure


```bash

multimodal-summarizer-ai/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ summary_app.py
â”œâ”€â”€ core/
â”‚   â””â”€â”€ nlp_tasks.py
â”œâ”€â”€ data/                #data/ not included in repo for efficient cloning
â”‚   â””â”€â”€ chunks.json
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ metrics.py
â”‚   â”œâ”€â”€ run_metrics.py
â”‚   â””â”€â”€ visualizations.py
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ summarizers.py
â”‚   â””â”€â”€ bart-meetingbank-finetuned/
â”‚       â”œâ”€â”€ config.json
â”‚       â”œâ”€â”€ generation_config.json
â”‚       â”œâ”€â”€ merges.txt
â”‚       â”œâ”€â”€ model.safetensors
â”‚       â”œâ”€â”€ special_tokens_map.json
â”‚       â”œâ”€â”€ tokenizer_config.json
â”‚       â””â”€â”€ vocab.json
â”œâ”€â”€ results/             #results/ not included in repo(will be auto-generated depending on data/ used)
â”‚   â”œâ”€â”€ summary_outputs.csv
â”‚   â””â”€â”€ model_metrics.csv
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â””â”€â”€ audio_handler.py
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ sample_summary_report.pdf
â”œâ”€â”€ images/
â”‚   â””â”€â”€ .png (screenshots)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

```

The fine-tuned BART model (~500MB) can be downloaded from [Google Drive](https://drive.google.com/drive/folders/1xgx6-y8fumi1zS4DdcBTkkb-RUrLlG6c?usp=drive_link).  
Place it inside: `models/bart-meetingbank-finetuned/`



## Setup & Installation

âœ… Clone Repo and Create Virtual Environment

```bash
git clone https://github.com/your-username/ multimodal-summarizer-ai.git
cd multimodal-summarizer-ai
python3 -m venv .venv
source .venv/bin/activate

```
âœ… Install Requirements

```bash
  pip install -r requirements.txt
```

âœ… Run the App

```bash
  streamlit run app/summary_app.py

```

# Future Work (Planned for Project + Research Phase)

2) Training custom summarizers for specialized domains

3) Adding Named Entity Recognition, keyword extraction, and more advanced analytics

# Acknowledgements

1) https://huggingface.co/docs/transformers/index

2) https://github.com/openai/whisper

3) https://github.com/Tiiiger/bert_score

4) https://github.com/google-research/google-research/tree/master/rouge

5) https://streamlit.io/


# License

This project is licensed under the MIT License.




