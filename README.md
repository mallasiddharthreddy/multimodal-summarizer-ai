
# Multimodal Summarizer AI

Audio, Text, and Document Summarization with Transformer Models + Evaluation UI


# Overview

This project enables users to summarize audio files, raw text, and .docx documents using state-of-the-art transformer models (BART, PEGASUS, T5). The Streamlit interface supports summary generation, model comparison, sentiment analysis, and evaluation metric display. A detailed PDF report is also downloadable.


# Key Features

âœ… Supports Audio, Text, and Document inputs

âœ… Uses Whisper for audio transcription

âœ… Offers BART, PEGASUS, and T5 summarizers

âœ… Generates summary reports as downloadable PDFs

âœ… Computes ROUGE, Cosine Similarity, and BERTScore

âœ… Includes sentiment analysis of input

âœ… Supports side-by-side model comparison and metric visualization


# Models Used

| Model   | Task Type    | Source                    |
| ------- | ------------ | ------------------------- |
| BART    | Abstractive  | `facebook/bart-large-cnn` |
| PEGASUS | Abstractive  | `google/pegasus-xsum`     |
| T5      | Abstractive  | `t5-small`                |
| Whisper | Audio â†’ Text | `openai/whisper`          |


# App Interface

### Home â€“ Upload Options
![Home Interface](images/ui_streamlit.png)

### Uploading an Audio File
![Uploading Audio File](images/uploaded_audio.png)

### Transcription and Sentiment Analysis
![Transcription + Sentiment](images/transcription_sentiment.png)

### Model Comparison and Metric Visualization (clicking on compare all models toggle from above)
![Comparison & Chart](images/model_comparison_chart.png)

### Choosing a Summarization Model based on metrics above
![Choose Model Dropdown](images/choose_model_dropdown.png)

### Generated Summary, Metrics, and PDF Export
![Summary + Metrics + PDF](images/summary_metrics_pdflink.png)


# Sample Summary Report
  
View a full example of the summary and evaluation for an uploaded audio file using the BART model:  
ðŸ‘‰ [Download Summary Report (PDF)](reports/summary_report-1.pdf)


# How It Works

1) Input: User uploads audio (.wav, .mp3), text, or document (.docx)

2) Processing:

2.1) Audio is transcribed using Whisper

2.2) Text is split into chunks (if long)

3) Summarization: Selected model (BART/PEGASUS/T5) generates summaries

4) Evaluation: Metrics are computed:

4.1) ROUGE-1 and ROUGE-L

4.2) Cosine Similarity (TF-IDF)

4.3) BERTScore

5) Sentiment Analysis: Basic polarity detection using TextBlob

6) Export: Generates and downloads a PDF summary report






## Evaluation & Benchmarking

Metrics auto-generated in:

```bash
  results/summary_outputs.csv
```
```bash
  results/model_metrics.csv
```
For graphing:

```bash
  python3 -m evaluation.visualizations
```


## Project Structure


```bash
  multimodal-summarizer-ai/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ summary_app.py
â”œâ”€â”€ core/
â”‚   â””â”€â”€ nlp_tasks.py
â”œâ”€â”€ data/                #data/ not included in repo for efficient cloning
â”‚   â””â”€â”€ chunks.json
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ metrics.py
â”‚   â”œâ”€â”€ run_metrics.py
â”‚   â””â”€â”€ visualizations.py
â”œâ”€â”€ models/
â”‚   â””â”€â”€ summarizers.py
â”œâ”€â”€ results/             #results/ not included in repo(will be auto-generated depending on data/ used)
â”‚   â”œâ”€â”€ summary_outputs.csv
â”‚   â””â”€â”€ model_metrics.csv
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â””â”€â”€ audio_handler.py
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ sample_summary_report.pdf
â”œâ”€â”€ images/
â”‚   â””â”€â”€.png (screenshots)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

```


## Setup & Installation

âœ… Clone Repo and Create Virtual Environment

```bash
git clone https://github.com/your-username/ multimodal-summarizer-ai.git
cd multimodal-summarizer-ai
python3 -m venv .venv
source .venv/bin/activate

```
âœ… Install Requirements

```bash
  pip install -r requirements.txt
```

âœ… Run the App

```bash
  streamlit run app/summary_app.py

```

# Deployment

This project is live here:

ðŸ‘‰ Launch the App on Streamlit Cloud

# Future Work (Planned for Project + Research Phase)

1) Fine-tuning BART/PEGASUS on domain-specific meeting datasets

2) Training custom summarizers for specialized domains

3) Adding Named Entity Recognition, keyword extraction, and more advanced analytics

# Acknowledgements

1) https://huggingface.co/docs/transformers/index

2) https://github.com/openai/whisper

3) https://github.com/Tiiiger/bert_score

4) https://github.com/google-research/google-research/tree/master/rouge

5) https://streamlit.io/


# License

This project is licensed under the MIT License.




